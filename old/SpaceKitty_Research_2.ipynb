{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings; warnings.filterwarnings('ignore')\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import GridSearchCV, LeaveOneGroupOut, ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.regularizers import l2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in raw data sets, training, tournament (val, test, live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_data_sets():\n",
    "    train = pd.read_csv('numerai_training_data.csv', index_col=0).drop('data_type', axis=1)\n",
    "    df = pd.read_csv('numerai_tournament_data.csv', index_col=0)\n",
    "    valid = df.loc[df['data_type']=='validation'].drop('data_type', axis=1)\n",
    "    test = df.loc[df['data_type']=='test'].drop('data_type', axis=1)\n",
    "    live = df.loc[df['data_type']=='live'].drop('data_type', axis=1)\n",
    "    return(train, valid, test, live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, valid, test, live = import_data_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>era</th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>feature3</th>\n",
       "      <th>feature4</th>\n",
       "      <th>feature5</th>\n",
       "      <th>feature6</th>\n",
       "      <th>feature7</th>\n",
       "      <th>feature8</th>\n",
       "      <th>feature9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature42</th>\n",
       "      <th>feature43</th>\n",
       "      <th>feature44</th>\n",
       "      <th>feature45</th>\n",
       "      <th>feature46</th>\n",
       "      <th>feature47</th>\n",
       "      <th>feature48</th>\n",
       "      <th>feature49</th>\n",
       "      <th>feature50</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>n5e99b4326e6f463</th>\n",
       "      <td>era1</td>\n",
       "      <td>0.64488</td>\n",
       "      <td>0.56167</td>\n",
       "      <td>0.72591</td>\n",
       "      <td>0.52219</td>\n",
       "      <td>0.49311</td>\n",
       "      <td>0.51511</td>\n",
       "      <td>0.45514</td>\n",
       "      <td>0.51007</td>\n",
       "      <td>0.56489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67751</td>\n",
       "      <td>0.43340</td>\n",
       "      <td>0.67009</td>\n",
       "      <td>0.50086</td>\n",
       "      <td>0.51208</td>\n",
       "      <td>0.58674</td>\n",
       "      <td>0.54358</td>\n",
       "      <td>0.58602</td>\n",
       "      <td>0.51818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ncf8fb21f31e74d8</th>\n",
       "      <td>era1</td>\n",
       "      <td>0.44203</td>\n",
       "      <td>0.42957</td>\n",
       "      <td>0.51861</td>\n",
       "      <td>0.38445</td>\n",
       "      <td>0.62049</td>\n",
       "      <td>0.49168</td>\n",
       "      <td>0.46444</td>\n",
       "      <td>0.54369</td>\n",
       "      <td>0.52228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.44734</td>\n",
       "      <td>0.47049</td>\n",
       "      <td>0.50980</td>\n",
       "      <td>0.57241</td>\n",
       "      <td>0.38253</td>\n",
       "      <td>0.52020</td>\n",
       "      <td>0.55781</td>\n",
       "      <td>0.55142</td>\n",
       "      <td>0.51869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n834cd2712b7e479</th>\n",
       "      <td>era1</td>\n",
       "      <td>0.36741</td>\n",
       "      <td>0.43188</td>\n",
       "      <td>0.52491</td>\n",
       "      <td>0.44392</td>\n",
       "      <td>0.52592</td>\n",
       "      <td>0.50014</td>\n",
       "      <td>0.32131</td>\n",
       "      <td>0.62067</td>\n",
       "      <td>0.49516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.39102</td>\n",
       "      <td>0.71896</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.50981</td>\n",
       "      <td>0.52993</td>\n",
       "      <td>0.53588</td>\n",
       "      <td>0.52843</td>\n",
       "      <td>0.50573</td>\n",
       "      <td>0.38799</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nf49d82d23f17475</th>\n",
       "      <td>era1</td>\n",
       "      <td>0.80707</td>\n",
       "      <td>0.56341</td>\n",
       "      <td>0.52526</td>\n",
       "      <td>0.66020</td>\n",
       "      <td>0.34807</td>\n",
       "      <td>0.64373</td>\n",
       "      <td>0.68063</td>\n",
       "      <td>0.50475</td>\n",
       "      <td>0.64483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54288</td>\n",
       "      <td>0.39457</td>\n",
       "      <td>0.61531</td>\n",
       "      <td>0.30979</td>\n",
       "      <td>0.51926</td>\n",
       "      <td>0.44679</td>\n",
       "      <td>0.45668</td>\n",
       "      <td>0.66750</td>\n",
       "      <td>0.60906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n7586ede71dd04e7</th>\n",
       "      <td>era1</td>\n",
       "      <td>0.35577</td>\n",
       "      <td>0.57219</td>\n",
       "      <td>0.61766</td>\n",
       "      <td>0.42305</td>\n",
       "      <td>0.49314</td>\n",
       "      <td>0.49894</td>\n",
       "      <td>0.61066</td>\n",
       "      <td>0.40629</td>\n",
       "      <td>0.59973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.48323</td>\n",
       "      <td>0.56839</td>\n",
       "      <td>0.59356</td>\n",
       "      <td>0.41716</td>\n",
       "      <td>0.51963</td>\n",
       "      <td>0.48346</td>\n",
       "      <td>0.52642</td>\n",
       "      <td>0.47278</td>\n",
       "      <td>0.43362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   era  feature1  feature2  feature3  feature4  feature5  \\\n",
       "id                                                                         \n",
       "n5e99b4326e6f463  era1   0.64488   0.56167   0.72591   0.52219   0.49311   \n",
       "ncf8fb21f31e74d8  era1   0.44203   0.42957   0.51861   0.38445   0.62049   \n",
       "n834cd2712b7e479  era1   0.36741   0.43188   0.52491   0.44392   0.52592   \n",
       "nf49d82d23f17475  era1   0.80707   0.56341   0.52526   0.66020   0.34807   \n",
       "n7586ede71dd04e7  era1   0.35577   0.57219   0.61766   0.42305   0.49314   \n",
       "\n",
       "                  feature6  feature7  feature8  feature9   ...    feature42  \\\n",
       "id                                                         ...                \n",
       "n5e99b4326e6f463   0.51511   0.45514   0.51007   0.56489   ...      0.67751   \n",
       "ncf8fb21f31e74d8   0.49168   0.46444   0.54369   0.52228   ...      0.44734   \n",
       "n834cd2712b7e479   0.50014   0.32131   0.62067   0.49516   ...      0.39102   \n",
       "nf49d82d23f17475   0.64373   0.68063   0.50475   0.64483   ...      0.54288   \n",
       "n7586ede71dd04e7   0.49894   0.61066   0.40629   0.59973   ...      0.48323   \n",
       "\n",
       "                  feature43  feature44  feature45  feature46  feature47  \\\n",
       "id                                                                        \n",
       "n5e99b4326e6f463    0.43340    0.67009    0.50086    0.51208    0.58674   \n",
       "ncf8fb21f31e74d8    0.47049    0.50980    0.57241    0.38253    0.52020   \n",
       "n834cd2712b7e479    0.71896    0.57458    0.50981    0.52993    0.53588   \n",
       "nf49d82d23f17475    0.39457    0.61531    0.30979    0.51926    0.44679   \n",
       "n7586ede71dd04e7    0.56839    0.59356    0.41716    0.51963    0.48346   \n",
       "\n",
       "                  feature48  feature49  feature50  target  \n",
       "id                                                         \n",
       "n5e99b4326e6f463    0.54358    0.58602    0.51818       0  \n",
       "ncf8fb21f31e74d8    0.55781    0.55142    0.51869       1  \n",
       "n834cd2712b7e479    0.52843    0.50573    0.38799       1  \n",
       "nf49d82d23f17475    0.45668    0.66750    0.60906       1  \n",
       "n7586ede71dd04e7    0.52642    0.47278    0.43362       1  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "era1 = train.loc[train.era==\"era1\"]\n",
    "era2 = train.loc[train.era==\"era2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJFXKApCkSlkAklQpC0CSKmUBSFKl/j8B2dUrT1w9uQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd4dbefe7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "era1.feature4.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvEYH7Pz6qFsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd4d9cc9400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "era2.feature4.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_cols = [f for f in train.columns if \"feature\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = train[feature_cols]\n",
    "x_val = valid[feature_cols]\n",
    "x_test = test[feature_cols]\n",
    "x_live = live[feature_cols]\n",
    "y_train = train['target']\n",
    "y_val = valid['target']\n",
    "\n",
    "\n",
    "train_eras = train['era'].values\n",
    "val_eras = valid['era'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def score_keras_model(model, x_val, y_val, eras):    \n",
    "    \n",
    "    print('Logloss: ' + str(log_loss(y_val.values, mod.predict_proba(x_val_pca))))\n",
    "    \n",
    "    val_logo = LeaveOneGroupOut()\n",
    "    scores = []\n",
    "    fail = 0\n",
    "    guessing = -log(.5)\n",
    "    \n",
    "    for _, index in val_logo.split(x_val, y_val, eras):\n",
    "        score = log_loss(y_val.iloc[index].values, model.predict(x_val.values[index,:]))\n",
    "        print(score)\n",
    "        if(score > guessing):\n",
    "            fail += 1\n",
    "            \n",
    "    print(fail / 12.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=42).fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train['cluster'] = kmeans.predict(x_train)\n",
    "x_val['cluster'] = kmeans.predict(x_val)\n",
    "x_test['cluster'] = kmeans.predict(x_test)\n",
    "x_live['cluster'] = kmeans.predict(x_live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    49807\n",
       "1    27085\n",
       "2    17411\n",
       "0    14102\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    7363\n",
       "1    4510\n",
       "2    2645\n",
       "0    2168\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    13130\n",
       "1     6962\n",
       "2     4352\n",
       "0     3249\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    528\n",
       "1    332\n",
       "2    232\n",
       "0    188\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_live['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compile_nn(input_dim):\n",
    "    \n",
    "    model = Sequential()    \n",
    "    model.add(Dense(24, input_dim=input_dim, activation='relu', init='normal', W_regularizer=l2(0.001)))    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    for i in range(0,4):        \n",
    "        model.add(Dense(128, activation='relu', init='normal', W_regularizer=l2(0.001)))\n",
    "        model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nets = []\n",
    "nn1 = compile_nn(x_train.shape[1])\n",
    "nn2 = compile_nn(x_train.shape[1])\n",
    "nn3 = compile_nn(x_train.shape[1])\n",
    "nn4 = compile_nn(x_train.shape[1])\n",
    "nets.append(nn1)\n",
    "nets.append(nn2)\n",
    "nets.append(nn3)\n",
    "nets.append(nn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14102 samples, validate on 2168 samples\n",
      "Epoch 1/10\n",
      "14102/14102 [==============================] - 1s - loss: 0.7418 - acc: 0.5089 - val_loss: 0.7064 - val_acc: 0.5148\n",
      "Epoch 2/10\n",
      "14102/14102 [==============================] - 0s - loss: 0.6982 - acc: 0.5121 - val_loss: 0.6937 - val_acc: 0.5148\n",
      "Epoch 3/10\n",
      "14102/14102 [==============================] - 0s - loss: 0.6932 - acc: 0.5119 - val_loss: 0.6928 - val_acc: 0.5148\n",
      "Epoch 4/10\n",
      "14102/14102 [==============================] - 0s - loss: 0.6930 - acc: 0.5119 - val_loss: 0.6928 - val_acc: 0.5148\n",
      "Epoch 5/10\n",
      "14102/14102 [==============================] - 0s - loss: 0.6929 - acc: 0.5120 - val_loss: 0.6928 - val_acc: 0.5148\n",
      "Epoch 6/10\n",
      "14102/14102 [==============================] - 0s - loss: 0.6929 - acc: 0.5119 - val_loss: 0.6928 - val_acc: 0.5148\n",
      "Epoch 7/10\n",
      "14102/14102 [==============================] - 0s - loss: 0.6929 - acc: 0.5119 - val_loss: 0.6927 - val_acc: 0.5148\n",
      "Epoch 8/10\n",
      "14102/14102 [==============================] - 0s - loss: 0.6929 - acc: 0.5119 - val_loss: 0.6928 - val_acc: 0.5148\n",
      "Epoch 9/10\n",
      "14102/14102 [==============================] - 0s - loss: 0.6929 - acc: 0.5119 - val_loss: 0.6928 - val_acc: 0.5148\n",
      "Epoch 10/10\n",
      "14102/14102 [==============================] - 0s - loss: 0.6929 - acc: 0.5120 - val_loss: 0.6928 - val_acc: 0.5148\n",
      "Train on 27085 samples, validate on 4510 samples\n",
      "Epoch 1/10\n",
      "27085/27085 [==============================] - 0s - loss: 0.7222 - acc: 0.5106 - val_loss: 0.6947 - val_acc: 0.4956\n",
      "Epoch 2/10\n",
      "27085/27085 [==============================] - 0s - loss: 0.6932 - acc: 0.5085 - val_loss: 0.6937 - val_acc: 0.5044\n",
      "Epoch 3/10\n",
      "27085/27085 [==============================] - 0s - loss: 0.6931 - acc: 0.5108 - val_loss: 0.6932 - val_acc: 0.5044\n",
      "Epoch 4/10\n",
      "27085/27085 [==============================] - 0s - loss: 0.6930 - acc: 0.5112 - val_loss: 0.6932 - val_acc: 0.5044\n",
      "Epoch 5/10\n",
      "27085/27085 [==============================] - 0s - loss: 0.6931 - acc: 0.5100 - val_loss: 0.6932 - val_acc: 0.5044\n",
      "Epoch 6/10\n",
      "27085/27085 [==============================] - 0s - loss: 0.6930 - acc: 0.5114 - val_loss: 0.6932 - val_acc: 0.5044\n",
      "Epoch 7/10\n",
      "27085/27085 [==============================] - 0s - loss: 0.6930 - acc: 0.5114 - val_loss: 0.6932 - val_acc: 0.5044\n",
      "Epoch 8/10\n",
      "27085/27085 [==============================] - 0s - loss: 0.6930 - acc: 0.5114 - val_loss: 0.6932 - val_acc: 0.5044\n",
      "Epoch 9/10\n",
      "27085/27085 [==============================] - 0s - loss: 0.6930 - acc: 0.5114 - val_loss: 0.6932 - val_acc: 0.5044\n",
      "Epoch 10/10\n",
      "27085/27085 [==============================] - 0s - loss: 0.6930 - acc: 0.5114 - val_loss: 0.6933 - val_acc: 0.5044\n",
      "Train on 17411 samples, validate on 2645 samples\n",
      "Epoch 1/10\n",
      "17411/17411 [==============================] - 0s - loss: 0.7363 - acc: 0.4964 - val_loss: 0.7011 - val_acc: 0.5168\n",
      "Epoch 2/10\n",
      "17411/17411 [==============================] - 0s - loss: 0.6958 - acc: 0.5001 - val_loss: 0.6934 - val_acc: 0.5168\n",
      "Epoch 3/10\n",
      "17411/17411 [==============================] - 0s - loss: 0.6933 - acc: 0.4966 - val_loss: 0.6930 - val_acc: 0.5168\n",
      "Epoch 4/10\n",
      "17411/17411 [==============================] - 0s - loss: 0.6932 - acc: 0.4986 - val_loss: 0.6930 - val_acc: 0.5168\n",
      "Epoch 5/10\n",
      "17411/17411 [==============================] - 0s - loss: 0.6932 - acc: 0.4987 - val_loss: 0.6930 - val_acc: 0.5168\n",
      "Epoch 6/10\n",
      "17411/17411 [==============================] - 0s - loss: 0.6932 - acc: 0.4995 - val_loss: 0.6932 - val_acc: 0.4832\n",
      "Epoch 7/10\n",
      "17411/17411 [==============================] - 0s - loss: 0.6932 - acc: 0.4988 - val_loss: 0.6930 - val_acc: 0.5168\n",
      "Epoch 8/10\n",
      "17411/17411 [==============================] - 0s - loss: 0.6932 - acc: 0.5012 - val_loss: 0.6930 - val_acc: 0.5168\n",
      "Epoch 9/10\n",
      "17411/17411 [==============================] - 0s - loss: 0.6932 - acc: 0.5003 - val_loss: 0.6930 - val_acc: 0.5168\n",
      "Epoch 10/10\n",
      "17411/17411 [==============================] - 0s - loss: 0.6932 - acc: 0.5008 - val_loss: 0.6932 - val_acc: 0.5168\n",
      "Train on 49807 samples, validate on 7363 samples\n",
      "Epoch 1/10\n",
      "49807/49807 [==============================] - 1s - loss: 0.7092 - acc: 0.4955 - val_loss: 0.6932 - val_acc: 0.5051\n",
      "Epoch 2/10\n",
      "49807/49807 [==============================] - 1s - loss: 0.6932 - acc: 0.4982 - val_loss: 0.6932 - val_acc: 0.4949\n",
      "Epoch 3/10\n",
      "49807/49807 [==============================] - 1s - loss: 0.6932 - acc: 0.4983 - val_loss: 0.6931 - val_acc: 0.5051\n",
      "Epoch 4/10\n",
      "49807/49807 [==============================] - 1s - loss: 0.6932 - acc: 0.4972 - val_loss: 0.6931 - val_acc: 0.5051\n",
      "Epoch 5/10\n",
      "49807/49807 [==============================] - 1s - loss: 0.6932 - acc: 0.4999 - val_loss: 0.6932 - val_acc: 0.4949\n",
      "Epoch 6/10\n",
      "49807/49807 [==============================] - 1s - loss: 0.6932 - acc: 0.4951 - val_loss: 0.6932 - val_acc: 0.4949\n",
      "Epoch 7/10\n",
      "49807/49807 [==============================] - 1s - loss: 0.6932 - acc: 0.4964 - val_loss: 0.6932 - val_acc: 0.4949\n",
      "Epoch 8/10\n",
      "49807/49807 [==============================] - 1s - loss: 0.6932 - acc: 0.5017 - val_loss: 0.6931 - val_acc: 0.5051\n",
      "Epoch 9/10\n",
      "49807/49807 [==============================] - 1s - loss: 0.6932 - acc: 0.4965 - val_loss: 0.6931 - val_acc: 0.5051\n",
      "Epoch 10/10\n",
      "49807/49807 [==============================] - 1s - loss: 0.6932 - acc: 0.5006 - val_loss: 0.6931 - val_acc: 0.5051\n"
     ]
    }
   ],
   "source": [
    "fits = []\n",
    "for i in range(0,4):\n",
    "    nn = nets[i]\n",
    "    \n",
    "    xt = x_train.loc[x_train['cluster']==i].values\n",
    "    yt = y_train.loc[x_train['cluster']==i].values\n",
    "    xv = x_val.loc[x_val['cluster']==i].values\n",
    "    yv = y_val.loc[x_val['cluster']==i].values\n",
    "    \n",
    "    nn.fit(xt, yt, validation_data=(xv, yv),\n",
    "           nb_epoch=10, batch_size=256, verbose=1)\n",
    "    \n",
    "    fits.append(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2441\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2442\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pred'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6fdbe6cdbaf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1964\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1966\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1969\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1973\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3589\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3590\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3591\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3592\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2442\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2443\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2444\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2446\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5280)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20523)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item (pandas/_libs/hashtable.c:20477)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pred'"
     ]
    }
   ],
   "source": [
    "df_pred = x_val\n",
    "\n",
    "for i in range(0,4):\n",
    "    nn = nets[i]\n",
    "    p = nn.predict(x_val.loc[x_val['cluster']==i].values)\n",
    "    df_pred['pred'].loc[x_val['cluster']==i] = p\n",
    "    \n",
    "df_pred.head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: 0.693223366556\n",
      "0.693122177049\n",
      "0.693196973545\n",
      "0.692975956408\n",
      "0.693058342165\n",
      "0.693136847739\n",
      "0.692947238747\n",
      "0.693346140927\n",
      "0.693254197692\n",
      "0.693596618931\n",
      "0.693635535614\n",
      "0.693149273616\n",
      "0.693251757821\n",
      "0.583333333333\n"
     ]
    }
   ],
   "source": [
    "score_keras_model(nn, x_val, y_val, val_eras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_pred = pd.concat([x_val,test,live])\n",
    "\n",
    "#Keras model\n",
    "nn_preds = pd.Series(nn.predict(to_pred.values)[:,0])\n",
    "\n",
    "#to_vote = pd.concat([rf_1_preds, rf_2_preds], axis=1)\n",
    "\n",
    "# Ensemble Tree\n",
    "#ens_preds = pd.Series(tree.predict_proba(to_vote.values)[:,1])\n",
    "#ens_preds = to_vote.mean(axis=1)\n",
    "ens_preds = nn_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    45630.000000\n",
       "mean         0.503124\n",
       "std          0.004284\n",
       "min          0.498657\n",
       "25%          0.499918\n",
       "50%          0.502135\n",
       "75%          0.505005\n",
       "max          0.534094\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_preds.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96144</td>\n",
       "      <td>0.517328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17982</td>\n",
       "      <td>0.523370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96161</td>\n",
       "      <td>0.486145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53895</td>\n",
       "      <td>0.494751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7267</td>\n",
       "      <td>0.510167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  probability\n",
       "0  96144     0.517328\n",
       "1  17982     0.523370\n",
       "2  96161     0.486145\n",
       "3  53895     0.494751\n",
       "4   7267     0.510167"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.concat([pd.Series(to_pred.index), pd.Series(ens_preds)], axis=1)\n",
    "sub.columns = ['id', 'probability']\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('sub_62_1_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
